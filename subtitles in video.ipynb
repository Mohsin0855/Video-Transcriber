{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMcPXyMguL9wl4BBRjWTzz2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import cv2\n","import whisper\n","import os\n","from moviepy.editor import ImageSequenceClip, AudioFileClip, VideoFileClip\n","from tqdm import tqdm\n","\n","class VideoTranscriber:\n","    def __init__(self, model_path, video_path):\n","        self.model = whisper.load_model(model_path)\n","        self.video_path = video_path\n","        self.audio_path = ''\n","        self.text_array = []\n","        self.fps = 0\n","        self.char_width = 0\n","\n","    def extract_audio(self):\n","        print('Extracting audio')\n","        audio_path = os.path.join(os.path.dirname(self.video_path), \"audio.mp3\")\n","        video = VideoFileClip(self.video_path)\n","        audio = video.audio\n","        audio.write_audiofile(audio_path)\n","        self.audio_path = audio_path\n","        print('Audio extracted')\n","\n","    def transcribe_video(self):\n","        print('Transcribing video')\n","        result = self.model.transcribe(self.audio_path)\n","        text = result[\"segments\"][0][\"text\"]\n","        textsize = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]\n","        cap = cv2.VideoCapture(self.video_path)\n","        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","        asp = 16/9\n","        ret, frame = cap.read()\n","        width = frame[:, int(int(width - 1 / asp * height) / 2):width - int((width - 1 / asp * height) / 2)].shape[1]\n","        width = width - (width * 0.1)\n","        self.fps = cap.get(cv2.CAP_PROP_FPS)\n","        self.char_width = int(textsize[0] / len(text))\n","\n","        for j in tqdm(result[\"segments\"]):\n","            lines = []\n","            text = j[\"text\"]\n","            end = j[\"end\"]\n","            start = j[\"start\"]\n","            total_frames = int((end - start) * self.fps)\n","            start = start * self.fps\n","            total_chars = len(text)\n","            words = text.split(\" \")\n","            i = 0\n","\n","            while i < len(words):\n","                words[i] = words[i].strip()\n","                if words[i] == \"\":\n","                    i += 1\n","                    continue\n","                length_in_pixels = (len(words[i]) + 1) * self.char_width\n","                remaining_pixels = width - length_in_pixels\n","                line = words[i]\n","\n","                while remaining_pixels > 0:\n","                    i += 1\n","                    if i >= len(words):\n","                        break\n","                    length_in_pixels = (len(words[i]) + 1) * self.char_width\n","                    remaining_pixels -= length_in_pixels\n","                    if remaining_pixels < 0:\n","                        continue\n","                    else:\n","                        line += \" \" + words[i]\n","\n","                line_array = [line, int(start) + 15, int(len(line) / total_chars * total_frames) + int(start) + 15]\n","                start = int(len(line) / total_chars * total_frames) + int(start)\n","                lines.append(line_array)\n","                self.text_array.append(line_array)\n","\n","        cap.release()\n","        print('Transcription complete')\n","\n","    def extract_frames(self, output_folder):\n","        print('Extracting frames')\n","        cap = cv2.VideoCapture(self.video_path)\n","        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","        asp = width / height\n","        N_frames = 0\n","\n","        while True:\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","\n","            frame = frame[:, :]\n","\n","            for i in self.text_array:\n","                if N_frames >= i[1] and N_frames <= i[2]:\n","                    text = i[0]\n","                    text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n","                    text_x = int((frame.shape[1] - text_size[0]) / 2)\n","                    text_y = int(height/2)\n","                    cv2.putText(frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n","                    break\n","\n","            cv2.imwrite(os.path.join(output_folder, str(N_frames) + \".jpg\"), frame)\n","            N_frames += 1\n","\n","        cap.release()\n","        print('Frames extracted')\n","\n","    def create_video(self, output_video_path):\n","        print('Creating video')\n","        image_folder = os.path.join(os.path.dirname(self.video_path), \"frames\")\n","        if not os.path.exists(image_folder):\n","            os.makedirs(image_folder)\n","\n","        self.extract_frames(image_folder)\n","\n","        images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n","        images.sort(key=lambda x: int(x.split(\".\")[0]))\n","\n","        frame = cv2.imread(os.path.join(image_folder, images[0]))\n","        height, width, layers = frame.shape\n","\n","        clip = ImageSequenceClip([os.path.join(image_folder, image) for image in images], fps=self.fps)\n","        audio = AudioFileClip(self.audio_path)\n","        clip = clip.set_audio(audio)\n","        clip.write_videofile(output_video_path)\n","\n","# Example usage\n","model_path = \"base\"\n","video_path = '/content/test2.mp4'\n","output_video_path =  '/content/output1.mp4'\n","\n","transcriber = VideoTranscriber(model_path,video_path)\n","transcriber.extract_audio()\n","transcriber.transcribe_video()\n","transcriber.create_video(output_video_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZzmKoVTSCkqL","executionInfo":{"status":"ok","timestamp":1712554023422,"user_tz":-300,"elapsed":67348,"user":{"displayName":"Mohsin Naseer","userId":"01231747355775196660"}},"outputId":"f6a16ef0-1b1e-4647-80d5-0db49bbd052f"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting audio\n","MoviePy - Writing audio in /content/audio.mp3\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["MoviePy - Done.\n","Audio extracted\n","Transcribing video\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:00<00:00, 24188.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Transcription complete\n","Creating video\n","Extracting frames\n","Frames extracted\n","Moviepy - Building video /content/output1.mp4.\n","MoviePy - Writing audio in output1TEMP_MPY_wvf_snd.mp3\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["MoviePy - Done.\n","Moviepy - Writing video /content/output1.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready /content/output1.mp4\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"95G8y9rCGHHE"},"execution_count":null,"outputs":[]}]}